{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will use tensorflow's `mnist` dataset, which allows us to classify handwritten numbers.\n",
    "\n",
    "The `mnist` dataset has been separated into:\n",
    "- 60,000 samples for training\n",
    "- 10,000 samples for testing\n",
    "\n",
    "## Feature\n",
    "\n",
    "Each data has two features: `image`, `label`\n",
    "- `image` has the class of `Image`, with the shape of (`x_pixel`, `y_pixel`, `color_channel`), e.g., (28, 28, 1), which means 28 by 28 pixel with the color channel of 1 meaning black and white.\n",
    "  - The `color_channel` will be 3 if it is colored (3 stands for Red, Green, and Blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TONOTE: Use tfds.load('dataset_name') to load datasets from TensorFlow\n",
    "data, metadata = tfds.load('mnist', as_supervised=True, with_info=True)\n",
    "# TONOTE: `as_supervised` tells TensorFlow to load the dataset in a supervised format, meaning each data point is returned as a tuple (input, label). For example, (image, label).\n",
    "# TONOTE: `with_info` includes metadata about the dataset, such as its description, version, and features. It’s like getting a user manual along with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the train and test data\n",
    "\n",
    "data_train = data['train']\n",
    "data_test = data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "metadata.features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `metadata.features['label']` is a ClassLabel, according to the tensorflow docs, it has an attribute called `.names` which returns the string names of the classes. Since the `num_classes=10`, the string name defaults to ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "class_names: list = metadata.features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TONOTE: Each pixel ranges from 0 to 255 (which is represented by 1 byte), it's a good idea to normalize the data before training, because all models work much between if the input values are scaled to smaller numbers.\n",
    "\n",
    "# TONOTE: We will do this for both the training and testing data. To not repeat ourselves, first we will create a function called normalizer, then using python's map function to map each data to the normalizer function\n",
    "\n",
    "def normalizer(images, labels):\n",
    "    # TONOTE: Since the image data are integers from 0 to 255, normalizing it will make it float instead, so we'd better convert the numbers to float32 first\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    # We want to convert the numbers from 0.0 to 255.0 to 0.0 and 1.0, we will divide them by 255\n",
    "    images = images / 255\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "data_train = data_train.map(normalizer)\n",
    "data_test = data_test.map(normalizer)\n",
    "\n",
    "# TONOTE: Save data to cache to process faster from the second time on\n",
    "data_train = data_train.cache()\n",
    "data_test = data_test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Create a new dataset that contains the first element from `data_train` using tensorflow's take function\n",
    "first_element = data_train.take(1)\n",
    "\n",
    "# Iterate over the first element to inspect it\n",
    "for images, labels in first_element:\n",
    "    # print(images, labels)\n",
    "    break\n",
    "# TONOTE: The `for` loop seems to not do anything, but with it, the variables `images` and `labels` have been set and ready to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Plotting a sample image\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(images)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Replot with to a grayscale image\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(images, cmap=plt.cm.binary) # TONOTE: The images actually only has one channel of color (1), that is the grayscale color, we still need to specify the cmap value here though. If we don't, the system will randomly adds colors to the plot instead of the grayscale.\n",
    "plt.colorbar() # Here we see that the value is between 0 to 1, instead of 0 to 255\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Let's show the first 25 images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i, (images, labels) in enumerate(data_train.take(25)): # TONOTE: We use `.take(n)` to get the fist `n` elements from data_train\n",
    "    # TONOTE: Use subplot of matplotlib to return multi-plots by specifying the number of row, column, and index\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(images, cmap=plt.cm.binary)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model to train our data\n",
    "\n",
    "Our data is of the shape (28, 28, 1), which is a 3D tensor. We will flatten this to a 1D tensor of shape (784,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# TONOTE: Flattening data which will be used as the input feature in the first layer\n",
    "flatten_data = keras.layers.Flatten(input_shape=(28,28,1))\n",
    "# TONOTE: The `keras.layers.Flatten` method will convert the (28, 28,1) input data into the shape of (28*28,) or (784,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    # TONOTE: This flatten data is the first layer, which acts like the Input Layer in other models. However, since the name `Input Layer` logically ties with `keras.layers.Input(...)` and the used of `keras.layers.Input(...)` in the sequential model should be avoided, it's best to not call it `Input Layer` here.\n",
    "    flatten_data, # first layer\n",
    "    # Hidden layer\n",
    "    keras.layers.Dense(1),\n",
    "    # Output layer\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax) # Because there are possible 10 answers, namely 0, 1, 2, ..., 9\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# # TONOTE:\n",
    "# keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "#     keras.layers.Dense(1),\n",
    "#     keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "# ])\n",
    "\n",
    "# # is the same as:\n",
    "\n",
    "# keras.Sequential([\n",
    "#     keras.layers.Dense(1, input_shape=(784,)),\n",
    "#     keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TONOTE: \n",
    "# keras.losses.SparseCategoricalCrossentropy() is a loss function, specifically designed for multi-class classification problems.\n",
    "# - It's a variant of the categorical cross-entropy loss function, but it's used when the labels are integers instead of one-hot encoded vectors. This means that instead of having a vector of probabilities for each class, you have a single integer representing the class label.\n",
    "\n",
    "# - SparseCategoricalCrossentropy is a good choice when:\n",
    "\n",
    "#   - We have a multi-class classification problem (e.g., image classification with multiple classes)\n",
    "#   - Our labels are integers (not one-hot encoded)\n",
    "#   - It's not specific to image classification, but it can be used for image classification problems. In fact, it's a popular choice for image classification tasks, especially when using convolutional neural networks (CNNs).\n",
    "\n",
    "# However, if we're working with a binary classification problem (e.g., image classification with only two classes), we might want to use keras.losses.BinaryCrossentropy() instead.\n",
    "\n",
    "# In general, the choice of loss function depends on the specific problem you're trying to solve, so it's always a good idea to consider the characteristics of your problem and choose the most suitable loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TONOTE: We also see that we can choose our metrics while compiling the model: `metrics=['accuracy']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Check the length of data_train and data_test\n",
    "print(f\"Training Data Length: {len(data_train)}\")\n",
    "print(f\"Testing Data Length: {len(data_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TONOTE: With so many training data, we should do some pre-processing to optimize the model's performance, making it run faster and more efficiently. Create a batch size to train the model in a batch of `n` every time, instead of running one by one.:\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "data_train = data_train.repeat().shuffle(60000).batch(batch_size)\n",
    "data_test = data_test.batch(batch_size)  # TONOTE: Since data_test only has 10000 records, it's not necessary to use the `.repeat()` and `.shuffle()` methods\n",
    "\n",
    "# TONOTE: TensorFlow data is a stream. By default, it does not repeat or cycle like the way some finite and static data (like Numpy array) does. We must explicitly use `.repeat()` to make the dataset cycle indefinitely for multiple epochs.\n",
    "\n",
    "# TONOTE: The shuffle value should be equal to the entire dataset size (number of dataset).\n",
    "\n",
    "# TONOTE: The `.batch()` method allows us to run the model in batch, instead of running one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Show the first image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(images, cmap=plt.cm.binary) # the `images` variable is actually the one set in the for loop in the immediate upper cell\n",
    "plt.colorbar() # we see that it goes from 0 to 1, instead of 0 to 255\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    data_train, \n",
    "    epochs=10,\n",
    "    steps_per_epoch=math.ceil(60000/batch_size)\n",
    ")\n",
    "# TONOTE: Since we train the model in batch, we need to tell it how many batches to expect by specifying the `steps_per_epoch` value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Show the first image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(images, cmap=plt.cm.binary) # the `images` variable is actually the one set in the for loop in the immediate upper cell\n",
    "plt.colorbar() # we see that it goes from 0 to 1, instead of 0 to 255\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that, with only one simple hidden layer, the accuracy of 42% is very low.\n",
    "\n",
    "# Try adding more layers with more neurons and activation function in the hidden layer\n",
    "model = keras.Sequential([\n",
    "    # First layer\n",
    "    flatten_data,\n",
    "    # Hidden layer\n",
    "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    # Output layer\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Retrain the model\n",
    "history = model.fit(\n",
    "    data_train,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=math.ceil(60000/batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a grid with multiple predictions, respectively marking correct and incorrect ones as blue and red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from matplotlib.container import BarContainer\n",
    "\n",
    "# TONOTE: Get the first batch of test data for a quick inspection and make predictions, as testing the entire dataset is too time consuming\n",
    "for images_test, labels_test in data_test.take(1):\n",
    "    # TONOTE: Convert the images_test and labels_test from TensorFlow tensors into numpy arrays so that they can be easily used with Matplotlib\n",
    "    images_test: np.ndarray = images_test.numpy()\n",
    "    labels_test: np.ndarray = labels_test.numpy()\n",
    "    # TONOTE: `images_test.shape` returns (32, 28, 28, 1), 32 is the batch_size, 28 is the height, 28 is the height, 1 is the color channel (grayscale). The shape already matches the one expected by `model.predict`, so we don't need to reshape it.\n",
    "    predictions: np.ndarray = model.predict(images_test)\n",
    "    \n",
    "# Function to plot individual images with their predictions\n",
    "def plot_image(i: int, predictions: np.ndarray, true_labels: np.ndarray, images: np.ndarray) -> None:\n",
    "    # Extract data for the specific index\n",
    "    prediction, true_label, image = predictions[i], true_labels[i], images[i]\n",
    "    prediction: np.ndarray\n",
    "    true_label: np.int64\n",
    "    image: np.ndarray\n",
    "    \n",
    "    # Remove grid and axis ticks for cleaner visualization\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # Display the image (only first channel as it's grayscale)\n",
    "    plt.imshow(image[...,0], cmap=plt.cm.binary)\n",
    "    # TONOTE: each image has the shape of (28, 28, 1), the ellipsis literal image[...,0] converts its shape to (28, 28). This is not necessary to convert the shape of (28, 28, 1) to (28, 28) though, as in this case, matplotlib can plot the exact same graph using both shapes, and it's just to show that it works when using the shape of (28, 28) though.\n",
    "    \n",
    "    # TONOTE: Next, we need to get the predicted label. `prediction` is a 1D numpy array with the shape of (10,0). The array may look like this: `[4.5158291e-12 2.1048035e-12 9.9999988e-01 8.6977693e-08 8.7193273e-12 2.4434133e-12 1.8026095e-11 1.8544542e-10 5.9155116e-08 7.4279107e-12]`, where each item is the predicted probability for each digit class (0 through 9). Therefore, to get the predicted label, we use `np.argmax` to return the \"index\" of the maximum value in the array\n",
    "    predicted_label: np.int64 = np.argmax(prediction)\n",
    "    \n",
    "    # Set color for the predicted label: blue for correct predictions, red for incorrect\n",
    "    color = 'blue' if predicted_label == true_label else 'red'\n",
    "    \n",
    "    print(f\"Metadata: {metadata}\")\n",
    "    print(f\"Metadata label: {metadata.features['label']}\")\n",
    "    print(f\"Metadata label name: {metadata.features['label'].names}\")\n",
    "    \n",
    "    # Add label showing: predicted digit, confidence percentage, and true digit\n",
    "    ## TONOTE: This shows the predicted label, probability or percentage of the prediction, and the true label. By showing these values, the model's prediction can be easily evaluated.\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(\n",
    "        class_names[predicted_label],\n",
    "        100*np.max(prediction),\n",
    "        class_names[true_label]\n",
    "    ), color=color)\n",
    "    # TONOTE: The three placeholders, `{}`, `{:2.0f}`, and `({})`, match their corresponding values, namely `class_names[predicted_label]`, 100*np.max(prediction)`, and `class_names[true_label]`\n",
    "\n",
    "# Function to plot probability distribution for each prediction\n",
    "def plot_value_array(i: int, predictions: np.ndarray, true_labels: np.ndarray) -> None:\n",
    "    prediction, true_label = predictions[i], true_labels[i]\n",
    "    prediction: np.ndarray\n",
    "    true_label: np.int64\n",
    "    \n",
    "    # Remove grid and axis ticks\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # Create bar chart of probability distribution (0-9)\n",
    "    graph: BarContainer = plt.bar(range(10), prediction, color=\"#777777\")\n",
    "    plt.ylim([0,1])  # Set y-axis limit to 0-1 for probabilities\n",
    "    ## TONOTE: Matplotlib's default behavior is to add a 10% margin to the y-axis limits to make the plot look more visually appealing. Setting `ylim([0,1])` is to ensure the y axis only range between 0 and 1, no more and no less.\n",
    "    \n",
    "    predicted_label: np.int64 = np.argmax(prediction)\n",
    "    \n",
    "    # Highlight bars: red for prediction, blue for true label\n",
    "    ## TONOTE: Since the labels range from 0 to 9, this is the same as x axis values. To color a bar in this case, we can use the `.set_color('some_color')` method of the bar graph on the specific bar identified by graph[index], like graph[predicted_label] or graph[true_label]\n",
    "    graph[predicted_label].set_color('red')\n",
    "    graph[true_label].set_color('blue')\n",
    "    \n",
    "# Set up grid dimensions for visualization\n",
    "num_row = 5\n",
    "num_column = 5\n",
    "num_images = num_row * num_column\n",
    "\n",
    "# Create figure with subplots for both images and their probability distributions\n",
    "plt.figure(figsize=(2*2*num_column, 2*num_row))\n",
    "for i in range(num_images):\n",
    "    # TONOTE: Create subplot for image (2*i+1 for left column) by specifying the number of rows, columns, and index (in this case: 1, 3, 5, ...)\n",
    "    plt.subplot(num_row, 2*num_column, 2*i+1)\n",
    "    plot_image(i, predictions, labels_test, images_test)\n",
    "    # TONOTE: Create subplot for probability distribution (2*i+2 for right column); The index in this case is 2, 4, 6, ...\n",
    "    plt.subplot(num_row, 2*num_column, 2*i+2)\n",
    "    plot_value_array(i, predictions, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the Use of Ellipsis and ndarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "images_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "images_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "images_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "images_test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "images_test[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "images_test[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "images_test[0][...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "images_test[0][...,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "images_test[0][...,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "images_test[0][...,0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# 4D array\n",
    "array_4d = np.random.rand(2, 3, 4, 5)\n",
    "print(array_4d.shape)  # Output: (2, 3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[[[1_1_1_1, 1_1_1_2, 1_1_1_3],\n",
    "   [2_1_1_1, 2_1_1_2, 2_1_1_3]],\n",
    "  \n",
    "  [[1_1_2_1, 1_1_2_2, 1_1_2_3],\n",
    "   [2_1_2_1, 2_1_2_2, 2_1_2_3]]],\n",
    "\n",
    " [[[1_2_1_1, 1_2_1_2, 1_2_1_3],\n",
    "   [2_2_1_1, 2_2_1_2, 2_2_1_3]],\n",
    "\n",
    "  [[1_2_2_1, 1_2_2_2, 1_2_2_3],\n",
    "   [2_2_2_1, 2_2_2_2, 2_2_2_3]]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "array_4d = np.random.rand(2, 3, 4, 5)\n",
    "array_4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "array_4d_2 = np.random.rand(4, 2, 2, 3)\n",
    "array_4d_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "array_4d_2[...,0]\n",
    "# TONOTE: By using the ellipsis convention [...,k], an array with the shape of (a_(1), a_(2), ..., a_(n-1), a_(n)) will be converted into the shape of (a_(1), a_(2), ..., a_(n-1)), where k ∈ ℕ & k < n.\n",
    "\n",
    "# TONOTE: If k = 0, it will take the value of the first index of each inner most column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "array_4d_2[...,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "array_4d_2[...,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "array_4d_2[...,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "array_4d_2[...,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "array_4d_2[0,...]\n",
    "\n",
    "# TONOTE: In this case, we convert a (4, 2, 2, 3) array into the shape of (2, 2, 3). It takes only the first index of the outer most column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "array_4d_2[0,...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# TONOTE: To take only some idex in the middle, use the `:` convention\n",
    "array_4d_2[:,:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "arr = np.array([[5,3,2,3],[4,8,2,6],[8,2,3,0]])\n",
    "print(arr)\n",
    "\n",
    "# Ellipsis literal\n",
    "print(f\"Ellipsis literal output:- {arr[...,1]}.\")\n",
    "\n",
    "# general slice notation\n",
    "print(f\"general slice notation output:- {arr[:,1]}\")\n",
    "\n",
    "# Python Ellipsis \n",
    "print(f\"Python Ellipsis output:- {arr[Ellipsis, 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "arr[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "arr[...,0].shape == (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "my_images = np.random.randint(0, 3, size=(3, 3))\n",
    "my_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Default Behavior of Matplotlib's color map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# TONOTE: No color mapping is set, but Matplotlib assigns random colors to the graph by default\n",
    "plt.imshow(my_images)\n",
    "plt.show()\n",
    "\n",
    "# TONOTE: We see that, even if the my_images doesn't have a color channel, the system still randomly assigns colors to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "my_images_2 = np.random.rand(3, 3)\n",
    "my_images_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt.imshow(my_images, cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "# TONOTE: We have to set the cmap=plt.cm.binary to get the grayscale graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Create a sample RGBA image\n",
    "images_rgba = np.random.randint(0, 256, size=(256, 256, 4), dtype=np.uint8)\n",
    "\n",
    "plt.imshow(images_rgba)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt.imshow(images_rgba, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "np.argmax(predictions[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed Key Learning Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data Batch Processing**\n",
    "   - When testing models, processing the entire dataset can be time-consuming\n",
    "   - Using `.take(1)` helps us get a small batch for quick inspection\n",
    "   - Example: `data_test.take(1)` gets first batch of 32 images\n",
    "\n",
    "2. **Data Type Conversion**\n",
    "   - TensorFlow tensors need conversion to NumPy arrays for Matplotlib compatibility\n",
    "   - Using `.numpy()` converts TensorFlow tensors to NumPy arrays\n",
    "   - Important for visualization and manipulation\n",
    "   - Example: `images_test = images_test.numpy()`\n",
    "\n",
    "3. **Image Shape Understanding**\n",
    "   - Image shape: `(32, 28, 28, 1)`\n",
    "     - 32: batch size (number of images)\n",
    "     - 28: image height in pixels\n",
    "     - 28: image width in pixels\n",
    "     - 1: color channel (grayscale)\n",
    "\n",
    "4. **Image Dimension Handling**\n",
    "   - Ellipsis notation `image[...,0]` converts shape from `(28, 28, 1)` to `(28, 28)`\n",
    "   - Both shapes work with Matplotlib\n",
    "   - Example:\n",
    "     ```python\n",
    "     # Both work the same\n",
    "     plt.imshow(image[...,0])  # Shape: (28, 28)\n",
    "     plt.imshow(image)         # Shape: (28, 28, 1)\n",
    "     ```\n",
    "\n",
    "5. **Prediction Array Understanding**\n",
    "   - Model outputs 1D array with 10 probabilities (0-9)\n",
    "   - Example output:\n",
    "     ```python\n",
    "     [4.5e-12, 2.1e-12, 0.99999, 8.6e-08, 8.7e-12, 2.4e-12, 1.8e-11, 1.8e-10, 5.9e-08, 7.4e-12]\n",
    "     ```\n",
    "   - `np.argmax()` finds index with highest probability (predicted digit)\n",
    "\n",
    "6. **Matplotlib Visualization Controls**\n",
    "   - Y-axis limits control using `plt.ylim([0,1])`\n",
    "   - Prevents default 10% margin addition\n",
    "   - Ensures probability visualization stays between 0 and 1\n",
    "\n",
    "7. **Bar Chart Color Manipulation**\n",
    "   - Bar graphs stored as `BarContainer` objects\n",
    "   - Individual bars accessible by index\n",
    "   - Color coding:\n",
    "     - Red: predicted label\n",
    "     - Blue: true label\n",
    "   - Example: `graph[predicted_label].set_color('red')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed Model Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data Acquisition**\n",
    "   - Import MNIST dataset using TensorFlow datasets\n",
    "   - Dataset contains 70,000 grayscale images of handwritten digits\n",
    "   - Split into training (60,000) and test (10,000) sets\n",
    "\n",
    "2. **Data Preprocessing**\n",
    "   - Normalize pixel values from 0-255 to 0-1 range\n",
    "   - Convert data to TensorFlow dataset format\n",
    "   - Create batches for efficient processing\n",
    "   - Apply prefetch for optimization\n",
    "\n",
    "3. **Model Architecture**\n",
    "   - Create sequential model\n",
    "   - Add Flatten layer to convert 2D images to 1D arrays\n",
    "   - Add Dense layers with appropriate activation functions\n",
    "   - Configure output layer with 10 neurons (0-9 digits)\n",
    "\n",
    "4. **Model Configuration**\n",
    "   - Set loss function (`keras.losses.SparseCategoricalCrossentropy()`)\n",
    "   - Choose optimizer (Adam)\n",
    "   - Define metrics (accuracy)\n",
    "\n",
    "5. **Training**\n",
    "   - Feed training data through model\n",
    "   - Adjust weights based on loss\n",
    "   - Monitor accuracy improvements\n",
    "   - Validate against test data\n",
    "\n",
    "6. **Testing and Visualization**\n",
    "   - Select batch of test images\n",
    "   - Make predictions\n",
    "   - Display results in grid format:\n",
    "     - Left column: actual images with predictions\n",
    "     - Right column: probability distributions\n",
    "   - Color-code correct (blue) and incorrect (red) predictions\n",
    "\n",
    "7. **Results Analysis**\n",
    "   - Examine prediction accuracy\n",
    "   - Analyze confidence levels\n",
    "   - Identify patterns in misclassifications\n",
    "   - Evaluate model performance metrics\n",
    "\n",
    "This process creates a complete pipeline from raw data to trained model with visual verification of results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
